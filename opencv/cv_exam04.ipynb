{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<<이미지 처리>>\n",
    "1. 사상(mapping)은 화소들의 배치를 변경할 때 입력영상의 좌표가 새롭게 배치될 영상의\n",
    "   목적영상의 좌표를 찾아서 화소값을 옮기는 것을 말한다.\n",
    "   - 순방향사상\n",
    "   - 역방향사상\n",
    "   \n",
    "2. 오버랩(overlap) 홀(hole)을 사상에서 발생된다.\n",
    "   - 홀(hole) : 목적영상의 좌표를 만드는 과정에서 사상되지 않은 화소\n",
    "   - 오버랩(overlap) : 목적영상 += 원본 여러 개의 화소 (원본 여러 개의 화소를 하나의 목적영상의 화소로 사상되는 것)\n",
    "   \n",
    "3. 방법(보간법 interpolation) : 목적 영ㅎ상에서 홀의 화소들을 채우고 오버랩이 되지 않게 화소들을 배치하여 목적영상을 만드는 기법\n",
    "\n",
    "4. 보간법 종류 : 최근접 이웃 보간법, 양선형 보간법, 3차회선 보간법\n",
    "   - 최근접 이웃 보간법 : 목적영상을 만드는 과정에서 홀이 되어 할당 받지 못하는 화소들의 값을 찾을때\n",
    "                          가장 가깝게 이웃한 입력 영상의 화소값을 가져오는 방법\n",
    "   - 양선형 보간법 : 선형 보간을 두번에 걸쳐서 하는 보간법\n",
    "   \n",
    "5. cv2.resize(),cv2.remap(), cv2.warpAffine(), cv2.warpPerspective() -> 보간법에 따른 옵션을 사용\n",
    "  ex) cv2.INTER_NEAREST, INTER_LINEAR INTER_CUBIC\n",
    "  \n",
    "6. 2*3 크기의 어파인 변환 행렬을 이용해서 크기변경, 회전, 평행 이동등을 복합적으로 사용한다.\n",
    "     cv2.getAffineTransform(), getRotationMatrix2D() 로 어파인 변환 행렬을 만들어\n",
    "     CV2.warpAffine()로 어파인 변환을 수행한다\n",
    "     \n",
    "7. 원근법 사용 : 눈에 보이는 3차원을 2차원의 평면으로 옮겨서 사물간의 거리를 반영 리턴\n",
    "                 warpPerspective![image.png](attachment:image.png)\n",
    "                 getPerspectiveTransform(src,dst[, solveMethod]) -> retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.53553391e-01  3.53553391e-01  2.10242181e+02]\n",
      " [-3.53553391e-01  3.53553391e-01  4.01780853e+02]]\n"
     ]
    }
   ],
   "source": [
    "#warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) -> dst\n",
    "# 1. 회전, 평행 이동 -> 유클리드 변환 (Euclidean transformation) \n",
    "# 2. 회전, 평행 이동, 확대 축소 -> 조합 상사변환(similarity transformation)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "img = cv2.imread('c:\\\\opencv_test\\\\1.jpg')\n",
    "h,w,c = img.shape\n",
    "h,w,c\n",
    "#getRotationMatrix2D(center, angle, scale) -> retval\n",
    "mat = cv2.getRotationMatrix2D((w/2,h/2),45,0.5)  #->  retval\n",
    "print(mat)\n",
    "\n",
    "affine_img = cv2.warpAffine(img,mat,(w,h),borderValue = (0,128,255))\n",
    "cv2.imshow(\"affine_img\",affine_img)\n",
    "\n",
    "dst = img//4\n",
    "affine_img02 = cv2.warpAffine(img,mat,(w,h),borderMode = cv2.BORDER_TRANSPARENT,dst = dst)\n",
    "cv2.imshow(\"affine_img02\",affine_img02)\n",
    "\n",
    "affine_img_near = cv2.warpAffine(img,mat,(w,h),flags = cv2.INTER_NEAREST)\n",
    "cv2.imshow(\"affine_img_near\",affine_img_near)\n",
    "\n",
    "affine_img_linear = cv2.warpAffine(img,mat,(w,h),flags = cv2.INTER_LINEAR)\n",
    "cv2.imshow(\"affine_img_linear\",affine_img_linear)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평행이동과 기울기  : sin, cos, tan, arcsin, arccos, arctan\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "img = cv2.imread('c:\\\\opencv_test\\\\1.jpg')\n",
    "w,h= img.shape[:2]\n",
    "\n",
    "r = math.tan(math.radians(15))\n",
    "\n",
    "mat = np.array([[1,0,0],\n",
    "                [r,1,0]], dtype = np.float32) #y축으로 15도 기울림\n",
    "\n",
    "mat2 = np.array([[1,r,0],\n",
    "                [0,1,0]], dtype = np.float32) #y축으로 15도 기울림\n",
    "\n",
    "affine_img = cv2.warpAffine(img,mat,(int(w+h*r),h))\n",
    "cv2.imshow(\"affine_img\",affine_img)\n",
    "\n",
    "affine_img2 = cv2.warpAffine(img,mat2,(int(w+h*r),h))\n",
    "cv2.imshow(\"affine_img2\",affine_img2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#affine_img = cv2.warpAffine(img,mat,(w,h),borderValue = (0,128,255))\n",
    "#cv2.imshow(\"affine_img\",affine_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "img = cv2.imread('c:\\\\opencv_test\\\\1.jpg')\n",
    "w,h= img.shape[:2]\n",
    "\n",
    "img_mark = img.copy()\n",
    "src_pt = np.array([[30,30],[50,200],[300,50]],dtype = np.uint8)\n",
    "\n",
    "img_mark = img.copy()\n",
    "for pt in src_pt:\n",
    "    cv2.drawMarker(img_mark,tuple(pt),(0,255,0),thickness=1)\n",
    "    \n",
    "cv2.imshow(\"affine_img\",img_mark)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
