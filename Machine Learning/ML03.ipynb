{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝\n",
    "4. 기계 학습시 데이터를 생성하고 변형모델에 입력할 경우 3가지 상황\n",
    "  - 기존 데이터 액세스하는 방법\n",
    "  - 랜덤 데이터 생성하는 방법\n",
    "  - model에 데이터를 입력 할때 구조와 대체 데이터 저장하는 방법\n",
    "  \n",
    "5. X, Y[출력 변수] : 데이터 형식의...\n",
    "\n",
    "6. 랜덤 데이터 생성하는 방법 : make_000로 시작하는 함수가 호출되는 데이터로 매개변수를 조절해서 레이블이 있는 데이터를 생성할 수 있다.\n",
    "\n",
    "   dataset                     데이터 종류         데이터수     차원         클래스 수        데이터분포조정\n",
    "make_blobs                 가우시안 데이터생성    n_samples    n_features    centers        cluster_std, cluster_box\n",
    "make_classification        n-class 분류용데이터   n_samples    n_features    n_classes      많다, 복잡하다.\n",
    "make_gaussian_quantiles    분류생성               n_samples    n_features    n_classes      mean, cov\n",
    "make_circle                원형분포               n_samples    2             2              factor\n",
    "\n",
    "7. 기계학습의 흐름\n",
    "  데이터 수집 -> 전처리 -> 데이터 분할 -> 학습하기 -> 테스트 평가하기\n",
    "  \n",
    "    1) 데이터 분할 : sklearn.model_selection.train_test_split\n",
    "    \n",
    "    2) 학습하기_(다양한 패턴의 알고리즘) : sklearn.ensemble.RandomForestClassifier 등 sklearn.ensemble.*\n",
    "        2-1) ensemble(집단학습) : 미학습 데이터에 대한 예측 능력을 평가하는 것\n",
    "                           : 단일 학습, 융합\n",
    "                           : 복잡한 학습 -> 독립적, 간단한 학습 -> 순차적\n",
    "                           : 랜덤포레스트, 부트스트랩의 두가지 관점으로 나뉜다.\n",
    "                    \n",
    "        2-2) RandomForest는 무슨 알고리즘 ?\n",
    "             부트스트랩 표본 추출 -> 학습데이터에서 n개의 샘플을 무작위로 선택\n",
    "             [부트스트랩의 표본에서 결정 나무를 생성] -> 임의의 d개의 특징된 양을 추출\n",
    "                                                         (목적함수에 따라 최적의 분할이 되는 특징량을 사용하여 노드를 분할)\n",
    "             예측 된 결과를 리턴\n",
    "    \n",
    "    3) 테스트 평가하기 : sklearn.metrics.accuracy_score 등    sklearn.metrics.*\n",
    "    \n",
    "    * 입출력함수가 정해져 있기 때문에 데이터 전체 구현하기전에 체크\n",
    "        model.fit(X,y), model.fit(X), model.predict(X) : 모델에서 테스트 까지\n",
    "        \n",
    "--------> 머신러닝\n",
    " 1. 다섯단계의 의미\n",
    " 2. 데이터셋 3가지\n",
    " 3. sklearn.metrics 모듈의 메소드 (클래스 분류결과)\n",
    "    TP(true Positive), TN(true negative), FP, FN\n",
    "    정답률_accuracy_score / 적합율 _ precision_score() / 재현율 _ recall_score() / 평가지표 산출률 Classification_report()\n",
    "    #F1 값 f1_score() / 매크로평균, 마이크로 평균값, 가중평균값 / 클래스 분류지표\n",
    "    \n",
    " 4. 단계별 코드를 전체 구현하면서 알고리즘 패턴을 숙지한다.\n",
    " \n",
    "==========================================================================================\n",
    "\n",
    "ML sklearn.metrics의 메소드를 살펴 보자.\n",
    "  8-1) confusion matrix형태의 데이터를 관리한다 : 클래스 분류 결과를 \"실제 클래스\"와 \"예측 클래스\"를 축으로 가진 형태\n",
    "  \n",
    "      실제 클래스, 예측클래스(두 값의 분류)  ->  4개의 종류로 나뉜다.\n",
    "      \n",
    "                              실제클래스     예측 클래스\n",
    "      TP(true positive)          T                T         (정답)\n",
    "      TN(true negative)          F                F         (정답)\n",
    "      FP(False Positive)         F                T         (오답)\n",
    "      FN(False negative)         T                F         (오답)\n",
    "      \n",
    "    ==============>  Predicted\n",
    "                         negative     Positive\n",
    "    Actual   negative       TN           FP\n",
    "             positive       FN           TP\n",
    "             \n",
    "  8-2) confusion_matrix() 생성해서 사용한다.\n",
    "  \n",
    "  8-3) accuracy_score()\n",
    "       \n",
    "       (TP+TN+FP+FN) / (TP+TN)\n",
    "  \n",
    "  8-4) 적합율(PPV : positive predictive value) _ precision_score()\n",
    "       precision = (TP+FP)/TP\n",
    "       FP가 커지면 적합율은 작아진다.\n",
    "  \n",
    "  8-5) 재현율 _ recall_score()\n",
    "       recall = (TP+FN)/TP\n",
    "       FN이 커지면 재현율은 작다\n",
    "       \n",
    "  8-6) #F1 measure 값 f1.score()\n",
    "           case 1 : precision + recall / 2*precision*recall\n",
    "           case 2 : 2*TP + FP + FN / 2 * TP\n",
    " \n",
    " 9. train_test_split() : ndarray객체 및 목록등을 둘로 나누어 리턴하는 기능 함수\n",
    "                         머신러닝 데이터를 훈련(학습)과 테스트로 분할한다.\n",
    "   \n",
    "                         데이터 검증방법 3가지\n",
    "                          1) 홀드 아웃 검증 : 데이터를 훈련 데이터와 테스트 데이터를 분할 한 다음\n",
    "                                              테스트 데이터를 사용하지 않는 방법, 테스트 데이터는 평가로 사용\n",
    "                          \n",
    "                          2) 교차검증(n겹) : 데이터를 n개의 그룹으로 나누어서 원하는 그룹을 하나 선택한 후 나머지\n",
    "                             데이터를 훈련데이터로 사용한다. 원하는 그룹을 하나 선택한 것은 테스트 평가\n",
    "                             테스트데이터에서 정밀도에 평균, 표준편차 구해서 평가 실행(5~10내외로 그룹을 나눈다.)\n",
    "                          \n",
    "                          3) LOOCV(Leave- ont-out Cross Validation) : 교차 검증시에 그룹개수와 데이터수가 같을 때 사용하는 검증방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape :  (506, 13)\n",
      "feature_names :  ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "target value :  [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_boston()\n",
    "print(\"data shape : \", data.data.shape)\n",
    "print(\"feature_names : \", data.feature_names)\n",
    "print(\"target value : \", data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape :  (150, 4)\n",
      "feature_names :  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "target value :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "class name :  ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "print(\"data shape : \", data.data.shape)\n",
    "print(\"feature_names : \", data.feature_names)\n",
    "print(\"target value : \", data.target)\n",
    "print(\"class name : \", data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape :  (178, 13)\n",
      "feature_names :  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "target value :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "class name :  ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_wine()\n",
    "print(\"data shape : \", data.data.shape)  # 데이터에 포함된 벡터값\n",
    "print(\"feature_names : \", data.feature_names)  # 각 요소의 이름\n",
    "print(\"target value : \", data.target)  # 클래스 (범주형 변수)\n",
    "print(\"class name : \", data.target_names)  # 클래스이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target value [0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 1 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0 2\n",
      " 1 1 2 0 0 1 1 1 0 2 1 2 0 2 2 0 2 0 1 2 2 1 2 2 0 1 2 1 1 2 1 0 1 1 1 0 0\n",
      " 1 1 2 2 1 1 1 2 2 0 2 1 1 1 1 1 0 0 1 0 2 0 2 0 0 1 0 1 1 0 2 1 0 1 1 1 2\n",
      " 0 2 2 0 0 1 2 0 0 1 1 0 0 0 2 1 0 1 2 0 1 2 2 0 0 2 0 2 1 0 0 1 0 2 1 2 0\n",
      " 2 2 2 0 1 1 1 1 2 2 1 1 0 1 2 2 0 0 2 1 1 1 0 0 0 1 1 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x,y = shuffle(data.data,data.target, random_state = 0)\n",
    "print(\"target value\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "data :  [ 5.  1.  4.  4. 11.  9.  3.  8.  2.  5.]\n",
      "lable :  [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#사용자 랜덤 데이터 생성\n",
    "data,target = datasets.make_multilabel_classification(n_samples=100, n_features=10, n_classes=5,n_labels = 3)\n",
    "print(type(data),type(target))\n",
    "print(\"data : \", data[0])\n",
    "print(\"lable : \", target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터를 가지고 학습 -> 평가 까지 전체 흐름을 살펴보자\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  #지표를 지정해서 n개의 결정나무 앙상블 학습 _wjdalfehfmf rngus\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#1. 데이터를 로드\n",
    "iris = datasets.load_iris()\n",
    "data,target = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 학습과 테스트로 나눈다.\n",
    "data_train, data_test, target_train, target_test= train_test_split(data,target,train_size = 0.8, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 모델 지정 = 알고리즘 종류\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. 학습\n",
    "model.fit(data_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "#5. 테스트 및 평가\n",
    "target_pred = model.predict(data_test)\n",
    "print(accuracy_score(target_test,target_pred))  #정답률을 계산한다.\n",
    "# 정답률_accuracy_score / 적합율 _ precision_score() / 재현율 _ recall_score() / 평가지표 산출률 Classification_report()\n",
    "# F1 값 f1_score() / 매크로평균, 마이크로 평균값, 가중평균값 / 클래스 분류지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [3 2]]\n",
      "[1 4 3 2]\n",
      "1\n",
      "4\n",
      "3\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 기본 클래스 y를 이용한 메소드를 살펴 보자.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "y_true = [0,0,0,0,0,1,1,1,1,1]\n",
    "y_pred = [0,1,1,1,1,0,0,0,1,1]\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "print(cm.flatten()) #1차원으로 풀자\n",
    "tn,fp,fn,tp = cm.flatten()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)\n",
    "sns.heatmap(cm,annot = True, cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [3 2]]\n"
     ]
    }
   ],
   "source": [
    "# 단어로 구현해 보자\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = ['A','A','A','A','A','B','B','B','B','B']\n",
    "y_pred = ['A','B','B','B','B','A','A','A','B','B']\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [3 2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true, y_pred,labels=['A','B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [4 1]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true, y_pred,labels=['B','A']))  # labels는 축의 순서를 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0]\n",
      " [0 2 1]\n",
      " [0 0 3]]\n",
      "[[0 0 0]\n",
      " [0 1 2]\n",
      " [0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "y_true = [0,0,0,1,1,1,2,2,2]\n",
    "y_pred = [0,1,1,1,1,2,2,2,2]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred,labels=[0,0,1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [3 2]]\n",
      "0.3\n",
      "0.3333333333333333\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# 정답률 확인\n",
    "from sklearn.metrics import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = [0,0,0,0,0,1,1,1,1,1]\n",
    "y_pred = [0,1,1,1,1,0,0,0,1,1]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "\n",
    "res = accuracy_score(y_true,y_pred)\n",
    "print(res)\n",
    "\n",
    "pre = precision_score(y_true,y_pred)\n",
    "print(pre)\n",
    "\n",
    "recall = recall_score(y_true,y_pred)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [3 2]]\n",
      "0.3333333333333333\n",
      "0.25\n",
      "[0.25       0.33333333]\n",
      "0.29166666666666663\n",
      "0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.25      0.20      0.22         5\n",
      "     class_1       0.33      0.40      0.36         5\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.29      0.30      0.29        10\n",
      "weighted avg       0.29      0.30      0.29        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 정답률 확인\n",
    "from sklearn.metrics import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = [0,0,0,0,0,1,1,1,1,1]\n",
    "y_pred = [0,1,1,1,1,0,0,0,1,1]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "\n",
    "pre = precision_score(y_true,y_pred)\n",
    "print(pre)\n",
    "\n",
    "pre = precision_score(y_true,y_pred,pos_label = 0)\n",
    "print(pre)\n",
    "\n",
    "pre = precision_score(y_true,y_pred,average = None)\n",
    "print(pre)\n",
    "\n",
    "# average = 'macro' : Positive, negative 교체해서 두 값의 산술평균을 리턴\n",
    "pre = precision_score(y_true,y_pred,average = 'macro')\n",
    "print(pre)\n",
    "\n",
    "# average = 'micro' : Positive, negative 교체해서 각각의 상태에서 TP와 FP, FN의 적합률 등을 리턴\n",
    "pre = precision_score(y_true,y_pred,average = 'micro')\n",
    "print(pre)  #precision = TP / (TP+FP) = (2+1) / ((2+1)+ (4+3)) = 0.3\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names = ['class_0','class_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [3 2]]\n",
      "[[2 3]\n",
      " [4 1]]\n"
     ]
    }
   ],
   "source": [
    "y_true = [0,0,0,0,0,1,1,1,1,1]\n",
    "y_pred = [0,1,1,1,1,0,0,0,1,1]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred,labels = [1,0])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.22222222222222224,\n",
      "       'precision': 0.25,\n",
      "       'recall': 0.2,\n",
      "       'support': 5},\n",
      " '1': {'f1-score': 0.3636363636363636,\n",
      "       'precision': 0.3333333333333333,\n",
      "       'recall': 0.4,\n",
      "       'support': 5},\n",
      " 'accuracy': 0.3,\n",
      " 'macro avg': {'f1-score': 0.29292929292929293,\n",
      "               'precision': 0.29166666666666663,\n",
      "               'recall': 0.30000000000000004,\n",
      "               'support': 10},\n",
      " 'weighted avg': {'f1-score': 0.29292929292929293,\n",
      "                  'precision': 0.29166666666666663,\n",
      "                  'recall': 0.3,\n",
      "                  'support': 10}}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "d = classification_report(y_true,y_pred,output_dict=True)\n",
    "pprint.pprint(d)\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0         1  accuracy  macro avg  weighted avg\n",
      "precision  0.250000  0.333333       0.3   0.291667      0.291667\n",
      "recall     0.200000  0.400000       0.3   0.300000      0.300000\n",
      "f1-score   0.222222  0.363636       0.3   0.292929      0.292929\n",
      "support    5.000000  5.000000       0.3  10.000000     10.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(d)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0]\n",
      " [0 2 1]\n",
      " [0 0 3]]\n",
      "[1.   0.5  0.75]\n",
      "0.75\n",
      "0.6666666666666666\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.50      0.67      0.57         3\n",
      "           2       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.67         9\n",
      "   macro avg       0.75      0.67      0.64         9\n",
      "weighted avg       0.75      0.67      0.64         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true_m = [0,0,0,1,1,1,2,2,2]\n",
    "y_pred_m = [0,1,1,1,1,2,2,2,2]\n",
    "print(confusion_matrix(y_true_m, y_pred_m))\n",
    "\n",
    "print(precision_score(y_true_m, y_pred_m, average = None))\n",
    "\n",
    "print(precision_score(y_true_m, y_pred_m, average = 'macro'))\n",
    "\n",
    "print(precision_score(y_true_m, y_pred_m, average = 'micro'))\n",
    "\n",
    "print(precision_score(y_true_m, y_pred_m, average = 'weighted'))\n",
    "print(classification_report(y_true_m, y_pred_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[array([6, 5, 3, 2, 7, 0, 1]), array([8, 4, 9])]\n",
      "<class 'list'>\n",
      "2\n",
      "[1 4 6 2 3 9 8]\n",
      "[7 0 5]\n",
      "=================================================\n",
      "[4 8 1 3 7 9 6]\n",
      "[2 0 5]\n"
     ]
    }
   ],
   "source": [
    "#sklearn.model_selection.train_test_split()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "a = np.arange(10)\n",
    "print(a)\n",
    "\n",
    "print(train_test_split(a))\n",
    "print(type(train_test_split(a)))\n",
    "print(len(train_test_split(a)))\n",
    "\n",
    "#1) 데이터 분할\n",
    "a_train, a_test = train_test_split(a)\n",
    "print(a_train)\n",
    "print(a_test)\n",
    "\n",
    "print(\"=================================================\")\n",
    "#2) 비율 지정, test_size, train_size = 0.25, -> 10*0.25 = 2.5 -> 3 (0.0~ 1.0) or 개수\n",
    "a_train, a_test = train_test_split(a, test_size=0.25)  #소수이하 절삭 10*0.25 = 2.5\n",
    "print(a_train)\n",
    "print(a_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "[6 7 9 5]\n",
      "[2 8 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"=================================================\")\n",
    "#4) 비율값 확인\n",
    "\n",
    "a_train, a_test = train_test_split(a, test_size=0.3, train_size = 0.4)  #소수이하 절삭 10*0.25 = 2.5\n",
    "print(a_train)\n",
    "print(a_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
