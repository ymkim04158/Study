{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN(Recurrent Neural Network) : 기존의 신경망은 입력된 데이터의 길이가 정해졌으나\n",
    "다양한 길이의 입력 시퀀스가 생겨나서 구현된 신경망(자연어처리, 스팸처리, (좋아요, 싫어요))\n",
    "ex)움직이는 객체의 경로를 저장해서 판별하는 것. 사람의 동작을 포함한 것은 RNN이 가진다.\n",
    "CNN / RNN -> GAN(생성모델) : 모션작곡, 자율주행, 홈트 등등\n",
    "\n",
    " - 입력과 출력을 시퀀스 단위로 처리하는 모델 <번역> 입력된문장 (단어) -> 출력된문장(단어)\n",
    " - 순환 신경망(RNN)과 재귀 신경망과는 완전 다른 개념의 모델\n",
    " - 노드 셀을 만들어서 입력과 출력 사이에서 순혼 할 수 있도록 구현된다.\n",
    "   Xt -> Cell(메모리 셀, Rnn 셀) -> Yt\n",
    " - 메모리셀은 각각의 시점 (t)을 가지고 바로 이전의 입력한 시점에서 전달해온 데이터를 가지고 재귀적인 활동을 한다. t+1 => Cell\n",
    " - t 시점에서 메모리 셀은 t-1 시점의 메모리 셀이 보낸 은닉상태의 값을 t 시점의 은닉상태 계산을 위한 입력 값이다.\n",
    "   ex) \"나는 금요일이 좋다\"\n",
    "     Xt ->        Cell(메모리 셀, Rnn 셀) -> Yt\n",
    "     \n",
    " - 일 대 다 : 입력하나 -> 셀 많이 -> 출력 많이 ex)사진하나 -> 여러개의 제목(사진제목이 단어 시퀀스 출력)\n",
    " - 다 대 일 : 입력 많이 -> 셀 많이 -> 출력 하나  ex) 감성분류, 스팸분류\n",
    " - 다 대 다 : 입력, 셀, 출력 많이 -> 번역처리\n",
    " \n",
    " - RNN의 은닉층 연산은 행렬연산.\n",
    " ex) model.add(simpleRNN(hidden_size), input_shape = ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 2, 3)              42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#ex) RNN층을 만들어 보자.\n",
    "from keras.models import *\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model. add(SimpleRNN(3, input_shape =(2,10), return_sequences = True))  #(None, 3)\n",
    "#model. add(SimpleRNN(3, batch_input_shape =(8,2,10), return_sequences = True))\n",
    "model.summary()\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 일련의 순서 신경망 '단어 4개 = 4개의 신경망\n",
    " - t 시점에서 메모리 셀은 t-1 시점의 메모리 셀이 보낸 은닉상태의 값을 t 시점의 은닉상태 계산을 위한 입력 값이다.\n",
    " - x(1)은 one-hot 연산을 구현한다.\n",
    " - s(t) : 넽웍에서 기억하는 공간\n",
    "   St = f(Uxt + Wst-1) 이때 함수로 비선형 함수가 된다.\n",
    " - Ot = t의 출력값 (문장에 출현 예측)\n",
    " \n",
    " - Ot = softmax(Vst)\n",
    " - LSTM(Long Short Term Memory) : 장단기 메모리로 은닉층의 메모리셀에 입력게이트, 소멸게이트, 출력게이트를\n",
    "   추가해서 불필요한 기억은 지우고 기억해야 되는 내용들을 저장한다. 각각의 게이트에는 시그모이드 함수가 존재한다.\n",
    "   시그모이드함수를 지나면 0,1 값이 나오게 되는데 이값들을 가지고 게이트가 조절된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.5830291  -0.6245827  -0.9303139   0.08409714]\n",
      " [ 0.5839203  -0.70715725 -0.8264405  -0.78320944]\n",
      " [-0.50610864 -0.5243976  -0.80418247  0.46438208]\n",
      " [ 0.28761122 -0.6394619  -0.79526025 -0.6175144 ]\n",
      " [ 0.4410587  -0.6094529  -0.7492597   0.16639543]\n",
      " [-0.40987927 -0.78644425 -0.8937732   0.271622  ]\n",
      " [-0.15111381 -0.5714589  -0.65993685 -0.6181043 ]\n",
      " [ 0.10160635 -0.73445964 -0.8578138  -0.86806923]\n",
      " [-0.31592685 -0.6302544  -0.5775584  -0.803648  ]\n",
      " [-0.06553799 -0.9549781  -0.7111652  -0.74051917]\n",
      " [ 0.60147214 -0.7582651  -0.42589512 -0.5682119 ]\n",
      " [-0.72933465 -0.80491954 -0.79919297 -0.6516444 ]\n",
      " [ 0.5158129  -0.22055125 -0.76340884 -0.16806725]\n",
      " [-0.6609605  -0.8379744  -0.84328884 -0.75087184]\n",
      " [ 0.1599396  -0.49723154 -0.7874414  -0.2591087 ]\n",
      " [-0.20234174 -0.4912249  -0.9168611   0.28574648]\n",
      " [ 0.5491436  -0.30608028 -0.67931956 -0.10864364]\n",
      " [ 0.3058426  -0.9089228  -0.709946   -0.71481   ]\n",
      " [-0.15423614 -0.0460488  -0.39968354 -0.03631032]\n",
      " [-0.21112077 -0.3084522  -0.9687222   0.0961644 ]\n",
      " [-0.62161297 -0.3843362  -0.26760527  0.15766196]\n",
      " [-0.30936584 -0.46129024 -0.8273942  -0.80014837]\n",
      " [ 0.25092846 -0.46703523 -0.86504525  0.12130131]\n",
      " [-0.5078969  -0.60219    -0.7440767   0.3482242 ]\n",
      " [ 0.0526182  -0.23528767 -0.7875013   0.0955385 ]\n",
      " [ 0.68620884  0.18180029 -0.4561949  -0.5869153 ]\n",
      " [-0.6029123  -0.5407831  -0.77334625 -0.22880535]\n",
      " [-0.03995394 -0.8872517  -0.9096461  -0.06220406]\n",
      " [-0.3301025   0.01150459 -0.5816713   0.3848861 ]\n",
      " [-0.25649175 -0.6043945  -0.83179307 -0.63289386]\n",
      " [ 0.16311567 -0.76800966 -0.8674904  -0.79517704]\n",
      " [-0.5590803  -0.4010665  -0.38977125 -0.146229  ]], shape=(32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#RNN은 텐서를 받을때 3D 텐서를 받는다\n",
    "#만일 2D 텐서가 들어온다면 3D로 변경해줘야 한다.\n",
    "\n",
    "inputs = np.random.random([32,10,8]).astype(np.float32)\n",
    "simple_rnn = tf.keras.layers.SimpleRNN(4)\n",
    "#print(inputs)\n",
    "\n",
    "output = simple_rnn(inputs) # The Output has shape '[32,4]'\n",
    "print(output)\n",
    "#return_sequences 히든레이어를 확인 시켜준다,.\n",
    "simple_rnn = tf.keras.layers.SimpleRNN(4, return_sequences = True, return_state = True)\n",
    "simple_rnn\n",
    "\n",
    "#whole_sequence_output has shape '[32,10,4]'\n",
    "# final_state has shape '[32,4]'\n",
    "whole_sequence_output, final_state = simple_rnn(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
