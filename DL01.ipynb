{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.19.2)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py) (1.19.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorboardX\n",
    "#!pip install jupyter-tensorboard\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install h5py\n",
    "!python3 -m pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. 임포트\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[12]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor([ 1  4  9 16], shape=(4,), dtype=int32)\n",
      "tf.Tensor([2 4 6 8], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#2. 행과 열을 만들자.\n",
    "matrix1 = tf.constant([[3,3]])\n",
    "matrix1\n",
    "\n",
    "matrix2 = tf.constant([[2],[2]])\n",
    "matrix2\n",
    "\n",
    "res = tf.matmul(matrix1,matrix2)\n",
    "print(res)\n",
    "\n",
    "#tf.constant([1,2,3,4,5,6])\n",
    "\n",
    "x = tf.constant(([1,2,3,4]))\n",
    "res02 = tf.math.multiply(x,x)\n",
    "print(res02)\n",
    "\n",
    "hap = tf.math.add(x,x)\n",
    "print(hap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([7.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([21.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([21.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#행렬 연산을 구현해 보자. 3.0, 2.0, 5.0 3.0*(2.0+5.0)\n",
    "input01 = tf.constant([3.0])\n",
    "input02 = tf.constant([2.0])\n",
    "input03 = tf.constant([5.0])\n",
    "\n",
    "hap = tf.math.add(input02,input03)\n",
    "res = tf.math.multiply(input01,hap)\n",
    "print(hap)\n",
    "print(res)\n",
    "\n",
    "res02 = tf.math.multiply(input01, tf.add(input02,input03))\n",
    "print(res02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, {} [[4]]\n"
     ]
    }
   ],
   "source": [
    "#3. 즉시 기본 실행\n",
    "tf.executing_eagerly()\n",
    "x = [[2]]\n",
    "m = tf.matmul(x,x)\n",
    "print(\"hello, {}\", format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "(2, 2)\n",
      "<dtype: 'int32'>\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]])>> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#4. 반환 작업\n",
    "a = tf.constant([[1,2],[3,4]])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.dtype)\n",
    "print(a.numpy,type(a.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#5. 브로드캐스팅(Broadcasting)지원\n",
    "b = tf.add(a,1)\n",
    "print(b)\n",
    "#6. 연산자 오버로딩 지원\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [12 20]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#7. Numpy 지원\n",
    "import numpy as np\n",
    "res = np.multiply(a,b)\n",
    "print(res,type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xed\\x99\\x8d\\xea\\xb8\\xb8\\xeb\\x8f\\x99'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b'\\xed\\x99\\x8d\\xea\\xb8\\xb8\\xeb\\x8f\\x99'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8. Variable\n",
    "name = tf.Variable(\"홍길동\",tf.string)\n",
    "kor = tf.Variable(100,tf.int32)\n",
    "eng = tf.Variable(90,tf.int32)\n",
    "tot = kor + eng\n",
    "print(name.numpy())\n",
    "name02 = tf.Variable([\"홍길동\"],tf.string)\n",
    "name02.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0000000e+00 1.2345000e+04 2.2987976e+00]\n",
      "[1 2 3 4 5]\n",
      "[12.3-4.85j  7.5-6.12j]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([3,12345,2.2987976],tf.float32)\n",
    "b = tf.Variable([1,2,3,4,5],tf.int32)\n",
    "c = tf.Variable([12.3-4.85j,7.5-6.12j],tf.complex64)\n",
    "a,b,c\n",
    "a.numpy(),b.numpy(),c.numpy()\n",
    "print(a.numpy())\n",
    "print(b.numpy())\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9. tensor 차원을 리턴 받자. tf.zeros()\n",
    "#배치 * 높이 * 너비 * 색상\n",
    "my_img = tf.zeros([10,299,299,3])\n",
    "res = tf.rank(my_img)\n",
    "print(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#10. 요소를 리턴\n",
    "my_v = tf.Variable([1,2,3,4])\n",
    "my_s = my_v[2]\n",
    "print(my_s.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11. tf의 객체를 Variable로 연동해 보자.\n",
    "my_val = tf.Variable(tf.zeros([2,2,3])) #변수\n",
    "my_val.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11. tf의 객체를 Variable로 연동해 보자.\n",
    "my_val = tf.constant(tf.zeros([2,2,3])) #상수\n",
    "my_val.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>\n"
     ]
    }
   ],
   "source": [
    "#12. 변수 자동 변환\n",
    "v = tf.Variable(0.0)\n",
    "v.numpy()\n",
    "\n",
    "w = v + 1 # w는 v값 기준으로 계산되는 tf.Tensor, 변수가 수식으로 사용하게 되면 tf.Tensor로 변환\n",
    "w\n",
    "\n",
    "v = tf.Variable(0.0)\n",
    "v.assign_add(1)\n",
    "print(v.read_value())\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "[[-1. -2.]\n",
      " [-3. -4.]\n",
      " [-5. -6.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "[[ 0.0855875   0.05591509]\n",
      " [ 0.14581393 -0.11724865]\n",
      " [ 0.0889082   0.02116547]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#3*2행의 float32값을 이용해서 값을 구현해보자.\n",
    "'''\n",
    "1  2\n",
    "3  4\n",
    "5  6\n",
    "'''\n",
    "A = tf.Variable([[1,2],[3,4],[5,6]], dtype = tf.float32)\n",
    "print(A.numpy())\n",
    "\n",
    "#전체  -값으로 변경해보자\n",
    "A.assign([[-1,-2],[-3,-4],[-5,-6]])\n",
    "print(A.numpy())\n",
    "\n",
    "# 3*2 행의 값을 모두 0으로 초기화 float 32\n",
    "A = tf.Variable(tf.zeros([3,2]),dtype = tf.float32)\n",
    "print(A.numpy())\n",
    "\n",
    "# 3*2의 행의 값을 요소모두를 평균은 0, 표준편차 0.1의 정규난수로 초기화를 시켜보자.\n",
    "#tf.random.normal()\n",
    "A = tf.Variable(tf.random.normal([3,2], mean = 0.0, stddev = 0.1, dtype = tf.dtypes.float32))\n",
    "print(A.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02355176  0.07517987]\n",
      " [-0.00063759  0.0445907 ]\n",
      " [-0.05809647 -0.08046322]]\n",
      "[[2.7916555 0.0829587]\n",
      " [2.9167614 2.2678843]\n",
      " [0.4901681 1.2679486]]\n"
     ]
    }
   ],
   "source": [
    "# 3*2의 행의 값을 요소모두를 평균은 0, 표준편차 0.1의 정규난수로 초기화를 시켜보자.\n",
    "#tf.random.normal()\n",
    "A = tf.Variable(tf.random.normal([3,2], mean = 0.0, stddev = 0.1, dtype = tf.dtypes.float32))\n",
    "print(A.numpy())\n",
    "\n",
    "# 3*2의 행의 값을 요소모두를 평균은 0, 표준편차 0.1의 정규난수로 초기화를 시켜보자.\n",
    "A = tf.Variable(tf.random.uniform([3,2], minval = -1, maxval = 3, dtype = tf.dtypes.float32))\n",
    "print(A.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.6931472 1.0986123]\n",
      "[0.7310586  0.8807971  0.95257413]\n",
      "[0.7615942 0.9640276 0.9950547]\n"
     ]
    }
   ],
   "source": [
    "#13. f(x) 표현하는 연산 시스템\n",
    "#log(x), exp(x), sin(x), cos(x), sigmoid(x), tanh(x) 등\n",
    "\n",
    "A = tf.constant([1,2,3],tf.float32)\n",
    "B = tf.math.log(A)\n",
    "print(B.numpy())\n",
    "\n",
    "B = tf.math.sigmoid(A)\n",
    "print(B.numpy())\n",
    "\n",
    "B = tf.math.tanh(A)\n",
    "print(B.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14. softmax : 로지스틱 함수를 다차원으로 만든것\n",
    "# 다항 로지스틱 회귀로 추력에 대한 확률분포로 네트워크 출력을 하는 정규화\n",
    "# 신경망의 활성화 함수로 자주 사용한다. (one - hot)\n",
    "# z = K로 실수값을 벡터를 받아서 입력숫자에 지수에 비례하는 K개의 확률분포 정규화 시킨것\n",
    "\n",
    "tf.nn.softmax(logits, axis = None, name = None)\n",
    "softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "\n",
    "tf.nn.softmax(x)\n",
    "입력 인수 x : 텐서, 정수 상수 텐서, 변수 상수 텐서, 변수 상수\n",
    "출력값\n",
    "    1. x의 각 요소마다 exp()를 계산해서 A에 할당\n",
    "    2. A의 요소를 모두 더해서 임의 변수 a에 넣는다.\n",
    "    3. A의 요소를 a로 나누어서 출력 텐서를 한다.\n",
    "    4. 출력 텐서의 각 요소의 값은 확률을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09003057 0.24472848 0.66524094]\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([1,2,3], tf.float32)\n",
    "B = tf.nn.softmax(A)\n",
    "print(B.numpy())  #확률분포\n",
    "\n",
    "B = tf.reduce_sum(A)\n",
    "print(B.numpy()) #확률분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([20. 36.], shape=(2,), dtype=float32) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[20. 36.]\n"
     ]
    }
   ],
   "source": [
    "#15. 사용자 오퍼레이션 만드는 방법\n",
    "'''\n",
    " @tf.function\n",
    " def 함수명():\n",
    "    연산\n",
    "    return\n",
    "'''\n",
    "\n",
    "#(a+b)*c myOP(a,b,c)\n",
    "\n",
    "def myOP(a,b,c):\n",
    "    t = tf.math.add(a,b)\n",
    "    return tf.math.multiply(t,c)\n",
    "\n",
    "A = tf.constant([1,2], tf.float32)\n",
    "\n",
    "B = tf.constant([3,4], tf.float32)\n",
    "\n",
    "C = tf.constant([5,6], tf.float32)\n",
    "\n",
    "D = myOP(A,B,C)\n",
    "print(D,type(D))\n",
    "print(D.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>, <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=2>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=4>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=6>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=8>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=9>)\n",
      "<__main__.MyModuleOne object at 0x000001FDA5E72BB0>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>\n"
     ]
    }
   ],
   "source": [
    "#16. 사용자 자료형 만들기\n",
    "# tf.Module를 상속받아 구현한다.\n",
    "# tf.Module 인스턴스는 Variable을 포함해서 다른 모듈들을 탐색할 수 있다.\n",
    "# trainable_variables = 훈련가능한 변수를 리턴\n",
    "\n",
    "class MyModuleOne(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.VO = tf.Variable(1.0)\n",
    "        self.VS = [tf.Variable(x) for x in range(10)]\n",
    "    \n",
    "    \n",
    "class MyOtherModule(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.m = MyModuleOne()\n",
    "        self.v = tf.Variable(10.0)\n",
    "        \n",
    "m = MyOtherModule()\n",
    "print(len(m.variables))\n",
    "print(m.variables)\n",
    "print(m.m)  #11은 m.m에서 다른값은 m.v에서 ....\n",
    "print(m.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1fdad6b3b20>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#17. 케라스\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation = \"relu\", name = \"layer1\"),\n",
    "        layers.Dense(3, activation = \"relu\", name = \"layer2\"),\n",
    "        layers.Dense(4, name = \"layer3\")\n",
    "    ]\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "Layer_0\n",
      "{'Layer_0': 0, 'Layer_1': 1, 'Layer_2': 2}\n",
      "1\n",
      "['Layer_0', 'Layer_1', 'Layer_2']\n"
     ]
    }
   ],
   "source": [
    "#18. 순차모델을 만들어 보자.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100,name = \"Layer_0\",input_shape = (1000,)),\n",
    "    tf.keras.layers.Dense(10,name = \"Layer_1\"),\n",
    "    tf.keras.layers.Dense(1,name = \"Layer_2\")\n",
    "    \n",
    "])\n",
    "\n",
    "#model.summary()\n",
    "print(type(model.layers[0]))\n",
    "print(model.layers[0].name)\n",
    "\n",
    "d = {k.name : i for i, k in enumerate(model.layers)}\n",
    "print(d)\n",
    "print(d['Layer_1'])\n",
    "\n",
    "layer_name = [k.name for k in model.layers]\n",
    "print(layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심층 신경망은 학습한 모든 변환을 수치 데이터 텐서에 적용하는 텐서 연산을 사용한다.\n",
    "ex) 텐서 덧셈, 텐서 곱셈\n",
    "\n",
    " tf.keras.layers.Dense(1, anme = 'Layer_2') -> 신경망을 만들었다. 층을 설정했다.\n",
    " \n",
    " 데이터 -> 학습구조모델링 -> 학습수행 -> 평가\n",
    " \n",
    " ex) 간단한 공식을 이용해서 값을 전달한 후 평가로 예측 값을 구현해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[ 3  5  7  9 11]\n",
      "y :  [ 3  5  7  9 11] predict :  [ 2.9999883  4.9999933  6.9999986  9.000004  11.000009 ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "# y = ax + b\n",
    "\n",
    "#[1단계] 데이터\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = x * 2 + 1\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "#[2단계]학습구조모델링\n",
    "model = Sequential()  # 레이어를 층층이 쌓아주는 메소드\n",
    "model.add(Dense(1, input_shape = (1,)))\n",
    "\n",
    "model.compile('SGD','mse')\n",
    "# SGD(Stochastic gradient descent : 확률적 경사 하강법)\n",
    "# mse(Mean Squared Error : 평균 제곱 오차)\n",
    "\n",
    "#[3단계] 학습수행 : 몇번 수행할지\n",
    "model.fit(x,y, epochs = 10000, verbose = 0)\n",
    "\n",
    "#[4단계] 평가\n",
    "print('y : ', y, 'predict : ', model.predict(x).flatten() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#20. tf.GradientTape API : 텐서플로는 자동 미분하는 API를 제공한다.\n",
    "# context 안에 실행된 모든 연산을 tape에 기록한다.\n",
    "# 후진방식 자동미분을 사용해서 tape에 기록된 연산을 결과를 계산한다.\n",
    "# 기울기를 구하는 클래스 : 정밀한 예측 모델을 만들려면 적당히 선택한 매개 변수에서\n",
    "# 예상한 값과 실제 결과를 비교해서 가능한 차이가 적게 매개변수를 조정하게된다.\n",
    "x = tf.ones((2,2))\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    y = tf.reduce_sum(x)\n",
    "    z = tf.multiply(y,y)\n",
    "    \n",
    "dz_dx = t.gradient(z,x) #입력텐서 x에 대한 z값\n",
    "\n",
    "for i in [0,1]:\n",
    "    for j in [0,1]:\n",
    "        #assert dz_dx[i][j] == 8.0\n",
    "        #dz_dx[i][j].numpy() == 8.0\n",
    "        print(dz_dx[i][j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
